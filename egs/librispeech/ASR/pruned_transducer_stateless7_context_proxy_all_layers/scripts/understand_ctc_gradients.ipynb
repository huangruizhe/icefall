{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/exp/rhuang/meta/icefall/egs/librispeech/ASR/pruned_transducer_stateless7_context_proxy_all_layers')\n",
    "sys.path.insert(0,'/exp/rhuang/meta/k2/k2/python')\n",
    "sys.path.insert(0,'/exp/rhuang/meta/k2/temp.linux-x86_64-cpython-310/lib')\n",
    "sys.path.insert(0,'/exp/rhuang/meta/icefall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import ctc_loss, log_softmax\n",
    "from torch.autograd import Variable\n",
    "import k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_supervisions(\n",
    "    targets, target_lengths, input_lengths\n",
    "):\n",
    "    \"\"\"\n",
    "    Encodes Lhotse's ``batch[\"supervisions\"]`` dict into\n",
    "    a pair of torch Tensor, and a list of transcription strings or token indexes\n",
    "\n",
    "    The supervision tensor has shape ``(batch_size, 3)``.\n",
    "    Its second dimension contains information about sequence index [0],\n",
    "    start frames [1] and num frames [2].\n",
    "\n",
    "    The batch items might become re-ordered during this operation -- the\n",
    "    returned tensor and list of strings are guaranteed to be consistent with\n",
    "    each other.\n",
    "    \"\"\"\n",
    "    # batch_size = targets.size(0)\n",
    "    batch_size = len(targets)\n",
    "    supervision_segments = torch.stack(\n",
    "        (\n",
    "            torch.arange(batch_size),\n",
    "            torch.zeros(batch_size),\n",
    "            input_lengths.cpu(),\n",
    "        ),\n",
    "        1,\n",
    "    ).to(torch.int32)\n",
    "\n",
    "    indices = torch.argsort(supervision_segments[:, 2], descending=True)\n",
    "    supervision_segments = supervision_segments[indices]\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # res = targets[indices].tolist()\n",
    "    # res_lengths = target_lengths[indices].tolist()\n",
    "    # res = [[i + 1 for i in l[:l_len]] for l, l_len in zip(res, res_lengths)]  # hard-coded for torchaudio\n",
    "    res = [targets[i] for i in indices]\n",
    "\n",
    "    return supervision_segments, res, indices\n",
    "\n",
    "def k2_ctc_loss(log_prob, targets, input_lengths, target_lengths, reduction='none'):\n",
    "    # `targets` is a list of lists\n",
    "\n",
    "    decoding_graph = k2.ctc_graph(targets, modified=False)\n",
    "    supervision_segments, texts, indices = encode_supervisions(targets, target_lengths, input_lengths)\n",
    "    # print(supervision_segments, texts, indices)\n",
    "    dense_fsa_vec = k2.DenseFsaVec(\n",
    "        log_prob.permute(1,0,2),  # TNC->NTC\n",
    "        supervision_segments,\n",
    "    )\n",
    "\n",
    "    if True:\n",
    "        loss = k2.ctc_loss(\n",
    "            decoding_graph=decoding_graph,\n",
    "            dense_fsa_vec=dense_fsa_vec,\n",
    "            reduction=reduction,\n",
    "            target_lengths=target_lengths,\n",
    "        )\n",
    "\n",
    "    if False:  # Also checkout: /exp/rhuang/meta/k2/k2/python/k2/ctc_loss.py and https://github.com/k2-fsa/icefall/blob/master/icefall/decode.py\n",
    "        \n",
    "        # lattice = k2.intersect_dense(\n",
    "        #     decoding_graph,\n",
    "        #     dense_fsa_vec,\n",
    "        #     10,\n",
    "        # )\n",
    "\n",
    "        lattice = k2.intersect_dense_pruned(\n",
    "            decoding_graph,\n",
    "            dense_fsa_vec,\n",
    "            search_beam=20,  # 15\n",
    "            output_beam=8,  # 6\n",
    "            min_active_states=30,\n",
    "            max_active_states=10000,\n",
    "        )\n",
    "\n",
    "        best_path = k2.shortest_path(lattice, use_double_scores=False)\n",
    "        forward_scores = best_path.get_tot_scores(use_double_scores=False, log_semiring=True)\n",
    "\n",
    "        loss = -forward_scores\n",
    "        if reduction == \"none\":\n",
    "            pass\n",
    "        elif reduction == \"sum\":\n",
    "            loss = loss.sum()\n",
    "        else:\n",
    "            assert reduction == \"mean\"\n",
    "            loss /= target_lengths\n",
    "            loss = loss.mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some example data\n",
    "output_dim = 5\n",
    "batch_size = 1\n",
    "sequence_length = 4\n",
    "log_probs = torch.randn(batch_size, sequence_length*2, output_dim).log_softmax(2).detach().requires_grad_()\n",
    "targets = torch.randint(1, output_dim, (batch_size, sequence_length), dtype=torch.long)\n",
    "input_lengths = torch.full((batch_size,), sequence_length*2, dtype=torch.long)\n",
    "target_lengths = torch.randint(1, sequence_length-1, (batch_size,), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8054, 0.0487, 0.0487, 0.0487, 0.0487],\n",
       "         [0.8054, 0.0487, 0.0487, 0.0487, 0.0487],\n",
       "         [0.5309, 0.0361, 0.3608, 0.0361, 0.0361],\n",
       "         [0.0462, 0.0251, 0.8785, 0.0251, 0.0251],\n",
       "         [0.3716, 0.0224, 0.5611, 0.0224, 0.0224],\n",
       "         [0.3382, 0.0368, 0.0368, 0.0368, 0.5515],\n",
       "         [0.8054, 0.0487, 0.0487, 0.0487, 0.0487],\n",
       "         [0.8054, 0.0487, 0.0487, 0.0487, 0.0487],\n",
       "         [0.8054, 0.0487, 0.0487, 0.0487, 0.0487],\n",
       "         [0.8054, 0.0487, 0.0487, 0.0487, 0.0487],\n",
       "         [0.8054, 0.0487, 0.0487, 0.0487, 0.0487]]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log_probs = [\n",
    "# [[-1.6678, -1.7028, -0.9742, -1.4975, -3.5766],\n",
    "# [-0.8538, -1.6253, -1.4779, -2.8868, -2.3700],\n",
    "# [-2.5472, -1.2712, -1.1831, -2.2954, -1.4518],\n",
    "# [-4.6883, -3.7046, -0.5502, -0.9947, -3.9358],\n",
    "# [-1.3619, -1.8677, -0.6211, -3.3785, -4.0219],\n",
    "# [-1.3728, -0.6234, -1.8358, -3.4717, -3.9147],\n",
    "# [-1.9166, -2.9598, -0.3028, -2.9376, -4.6766],\n",
    "# [-1.9206, -2.3894, -3.3004, -0.9705, -1.0613]],\n",
    "# ]\n",
    "# log_probs = torch.tensor(log_probs)\n",
    "# log_probs = log_probs.log_softmax(2).detach().requires_grad_()\n",
    "\n",
    "targets = torch.tensor([[2,4]], dtype=torch.long)\n",
    "target_lengths = torch.tensor([2,], dtype=torch.long)\n",
    "\n",
    "log_probs = [\n",
    "[[0.9, 0.02, 0.02, 0.02, 0.02],\n",
    "[0.9, 0.02, 0.02, 0.02, 0.02],\n",
    "[0.8, 0.02, 0.2, 0.02, 0.02],\n",
    "[0.1, 0.02, 0.7, 0.02, 0.02],\n",
    "[0.9, 0.02, 0.5, 0.02, 0.02],\n",
    "[0.5, 0.02, 0.02, 0.02, 0.3],\n",
    "[0.9, 0.02, 0.02, 0.02, 0.02],\n",
    "[0.9, 0.02, 0.02, 0.02, 0.02],\n",
    "[0.9, 0.02, 0.02, 0.02, 0.02],\n",
    "[0.9, 0.02, 0.02, 0.02, 0.02],\n",
    "[0.9, 0.02, 0.02, 0.02, 0.02]],\n",
    "]\n",
    "log_probs = torch.tensor(log_probs).log()\n",
    "log_probs = log_probs - torch.tensor([1.0, 0, 0, 0, 0]).view(1,1,-1)\n",
    "log_probs = log_probs.log_softmax(2).detach().requires_grad_()\n",
    "log_probs.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 5])\n",
      "tensor([8])\n",
      "tensor([[2, 4]])\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "print(log_probs.shape)\n",
    "print(input_lengths)\n",
    "print(targets)\n",
    "print(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of log_probs: tensor([[[-0.1412,  0.0607, -0.0034,  0.0746,  0.0093],\n",
      "         [-0.0042,  0.0641, -0.1096,  0.0186,  0.0312],\n",
      "         [-0.0046,  0.0870, -0.1938,  0.0336,  0.0779],\n",
      "         [-0.0007, -0.0017, -0.1267,  0.1233,  0.0059],\n",
      "         [-0.0008, -0.0159, -0.0005,  0.0114,  0.0058],\n",
      "         [ 0.0366, -0.0950,  0.0422,  0.0104,  0.0059],\n",
      "         [-0.1616, -0.0865,  0.2463,  0.0177, -0.0159],\n",
      "         [ 0.0418,  0.0306,  0.0123,  0.1263, -0.2109]]])\n"
     ]
    }
   ],
   "source": [
    "log_probs1 = log_probs.clone()\n",
    "log_probs1.retain_grad()  # Preserve the gradients for log_probs\n",
    "\n",
    "# Compute the CTC loss\n",
    "loss = ctc_loss(log_probs1.permute(1,0,2), targets, input_lengths, target_lengths)\n",
    "\n",
    "# Backpropagate the gradients\n",
    "loss.backward()\n",
    "\n",
    "# Print the gradients with respect to log_probs\n",
    "print(f\"Gradients of log_probs: {log_probs1.grad}\")\n",
    "\n",
    "# # Continue to backpropagate the gradients\n",
    "# # Check the gradients\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Gradients of {name}: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4006, grad_fn=<MeanBackward0>) tensor(2.0889, grad_fn=<MeanBackward0>)\n",
      "Gradients of log_probs: tensor([[[-0.5000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.5000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.5000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.5000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.5000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000, -0.5000],\n",
      "         [-0.5000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.5000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "log_probs2 = log_probs.clone()\n",
    "log_probs2.retain_grad()  # Preserve the gradients for log_probs\n",
    "\n",
    "loss_k2 = k2_ctc_loss(\n",
    "    log_probs2.permute(1,0,2), \n",
    "    [t[:lt].tolist() for t, lt in zip(targets, target_lengths)],  \n",
    "    input_lengths, \n",
    "    target_lengths,\n",
    "    reduction=\"mean\",\n",
    ")\n",
    "print(loss_k2, loss)\n",
    "\n",
    "loss_k2.backward()\n",
    "\n",
    "# Print the gradients with respect to log_probs\n",
    "print(f\"Gradients of log_probs: {log_probs2.grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of log_probs: tensor([[[-0.4654,  0.0000, -0.0346,  0.0000,  0.0000],\n",
      "         [-0.4441,  0.0000, -0.0550,  0.0000, -0.0009],\n",
      "         [-0.1224,  0.0000, -0.3754,  0.0000, -0.0022],\n",
      "         [-0.4340,  0.0000, -0.0519,  0.0000, -0.0141],\n",
      "         [-0.4321,  0.0000, -0.0292,  0.0000, -0.0387],\n",
      "         [-0.0595,  0.0000, -0.0035,  0.0000, -0.4370],\n",
      "         [-0.4558,  0.0000, -0.0010,  0.0000, -0.0433],\n",
      "         [-0.4806,  0.0000,  0.0000,  0.0000, -0.0194]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradients of log_probs: {log_probs2.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9184, 0.0204, 0.0204, 0.0204, 0.0204],\n",
       "          [0.9184, 0.0204, 0.0204, 0.0204, 0.0204],\n",
       "          [0.0943, 0.0189, 0.8491, 0.0189, 0.0189],\n",
       "          [0.9184, 0.0204, 0.0204, 0.0204, 0.0204],\n",
       "          [0.9184, 0.0204, 0.0204, 0.0204, 0.0204],\n",
       "          [0.5814, 0.0233, 0.0233, 0.0233, 0.3488],\n",
       "          [0.9184, 0.0204, 0.0204, 0.0204, 0.0204],\n",
       "          [0.9184, 0.0204, 0.0204, 0.0204, 0.0204]]], grad_fn=<ExpBackward0>),\n",
       " tensor([[2, 4]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.exp(), targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.9858, 6.8263], grad_fn=<ToCopyBackward0>),\n",
       " tensor(2.2232, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_k2, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.exp().sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6678, -1.7028, -0.9742, -1.4975, -3.5766],\n",
       "         [-0.8538, -1.6253, -1.4779, -2.8868, -2.3700],\n",
       "         [-2.5472, -1.2712, -1.1831, -2.2954, -1.4518],\n",
       "         [-4.6883, -3.7046, -0.5502, -0.9947, -3.9358],\n",
       "         [-1.3619, -1.8677, -0.6211, -3.3785, -4.0219],\n",
       "         [-1.3728, -0.6234, -1.8358, -3.4717, -3.9147],\n",
       "         [-1.9166, -2.9598, -0.3028, -2.9376, -4.6766],\n",
       "         [-1.9206, -2.3894, -3.3004, -0.9705, -1.0613]],\n",
       "\n",
       "        [[-1.3247, -1.6347, -1.5798, -2.3376, -1.4416],\n",
       "         [-3.1774, -3.2598, -0.4258, -1.4641, -3.3417],\n",
       "         [-0.8104, -2.6120, -2.0748, -2.4026, -1.3248],\n",
       "         [-1.5996, -1.7569, -2.8319, -0.9441, -1.7286],\n",
       "         [-1.3534, -2.1563, -2.6799, -1.1094, -1.4804],\n",
       "         [-2.0603, -0.8716, -1.8151, -1.3472, -3.4582],\n",
       "         [-1.5186, -1.5564, -1.3164, -2.1602, -1.6783],\n",
       "         [-2.1493, -2.1961, -1.6528, -1.5585, -0.9936]]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
