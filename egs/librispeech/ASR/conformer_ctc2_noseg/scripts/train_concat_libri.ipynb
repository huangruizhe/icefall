{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/exp/rhuang/meta/icefall/egs/librispeech/ASR/conformer_ctc2_noseg')\n",
    "sys.path.insert(0,'/exp/rhuang/meta/k2/k2/python')\n",
    "sys.path.insert(0,'/exp/rhuang/meta/k2/temp.linux-x86_64-cpython-310/lib')\n",
    "sys.path.insert(0,'/exp/rhuang/meta/icefall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/exp/rhuang/meta/icefall/egs/librispeech/ASR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/exp/rhuang/meta/icefall/egs/librispeech/ASR'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /exp/rhuang/meta/icefall/egs/librispeech/ASR\n",
    "%pwd  #look at the current work dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()\n",
    "\n",
    "parser = get_parser()\n",
    "LibriSpeechAsrDataModule.add_arguments(parser)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.exp_dir = \"/home/rhuang25/work/icefall/egs/librispeech/ASR/zipformer_no_seg/exp-test/\"\n",
    "args.bpe_model = \"/home/rhuang25/work/icefall/egs/librispeech/ASR/data/lang_bpe_500/bpe.model\"\n",
    "args.epoch = 2\n",
    "args.avg = 1\n",
    "\n",
    "# args.exp_dir = \"/home/rhuang25/work/icefall/egs/librispeech/ASR/zipformer/exp-ctc-rnnt\"\n",
    "# args.bpe_model = \"/home/rhuang25/work/icefall/egs/librispeech/ASR/data/lang_bpe_500/bpe.model\"\n",
    "# args.epoch = 40\n",
    "# args.avg = 1\n",
    "\n",
    "args.manifest_dir = \"/home/rhuang25/work/icefall/egs/librispeech/ASR/data/fbank/\"\n",
    "args.max_duration = 400\n",
    "args.world_size = 1\n",
    "args.start_epoch = 2\n",
    "args.full_libri = False\n",
    "args.use_transducer = False\n",
    "args.use_ctc = True\n",
    "args.ctc_loss_scale = 1.0\n",
    "args.ctc_beam_size = 4\n",
    "\n",
    "args.exp_dir = Path(args.exp_dir)\n",
    "args.manifest_dir = Path(args.manifest_dir)\n",
    "\n",
    "world_size = args.world_size\n",
    "assert world_size >= 1\n",
    "\n",
    "rank=0\n",
    "world_size=1\n",
    "args=args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libri_long_text [5]: 100%|██████████| 95/95 [00:11<00:00,  8.22it/s]\n",
      "libri_long_text [2]: 100%|██████████| 98/98 [00:12<00:00,  7.80it/s]\n",
      "libri_long_text [4]: 100%|██████████| 98/98 [00:12<00:00,  7.88it/s]\n",
      "libri_long_text [1]: 100%|██████████| 98/98 [00:12<00:00,  7.74it/s]\n",
      "libri_long_text [0]: 100%|██████████| 98/98 [00:12<00:00,  7.59it/s]\n",
      "libri_long_text [3]: 100%|██████████| 98/98 [00:14<00:00,  6.67it/s]\n",
      "100%|██████████| 585/585 [00:20<00:00, 28.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "\n",
    "params = get_params()\n",
    "params.update(vars(args))\n",
    "\n",
    "fix_random_seed(params.seed)\n",
    "if world_size > 1:\n",
    "    setup_dist(rank, world_size, params.master_port)\n",
    "\n",
    "# setup_logger(f\"{params.exp_dir}/log/log-train\")\n",
    "# logging.info(\"Training started\")\n",
    "\n",
    "# if args.tensorboard and rank == 0:\n",
    "#     tb_writer = SummaryWriter(log_dir=f\"{params.exp_dir}/tensorboard\")\n",
    "# else:\n",
    "#     tb_writer = None\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\", rank)\n",
    "logging.info(f\"Device: {device}\")\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(params.bpe_model)\n",
    "\n",
    "# <blk> is defined in local/train_bpe_model.py\n",
    "params.blank_id = sp.piece_to_id(\"<blk>\")\n",
    "params.vocab_size = sp.get_piece_size()\n",
    "\n",
    "if not params.use_transducer:\n",
    "    params.ctc_loss_scale = 1.0\n",
    "\n",
    "logging.info(params)\n",
    "\n",
    "logging.info(\"About to create model\")\n",
    "model = get_model(params)\n",
    "\n",
    "num_param = sum([p.numel() for p in model.parameters()])\n",
    "logging.info(f\"Number of model parameters: {num_param}\")\n",
    "\n",
    "assert params.save_every_n >= params.average_period\n",
    "model_avg: Optional[nn.Module] = None\n",
    "if rank == 0:\n",
    "    # model_avg is only used with rank 0\n",
    "    model_avg = copy.deepcopy(model).to(torch.float64)\n",
    "\n",
    "assert params.start_epoch > 0, params.start_epoch\n",
    "checkpoints = load_checkpoint_if_available(\n",
    "    params=params, model=model, model_avg=model_avg\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "if world_size > 1:\n",
    "    logging.info(\"Using DDP\")\n",
    "    model = DDP(model, device_ids=[rank], find_unused_parameters=True)\n",
    "\n",
    "optimizer = ScaledAdam(\n",
    "    get_parameter_groups_with_lrs(model, lr=params.base_lr, include_names=True),\n",
    "    lr=params.base_lr,  # should have no effect\n",
    "    clipping_scale=2.0,\n",
    ")\n",
    "\n",
    "scheduler = Eden(optimizer, params.lr_batches, params.lr_epochs)\n",
    "\n",
    "if checkpoints and \"optimizer\" in checkpoints:\n",
    "    logging.info(\"Loading optimizer state dict\")\n",
    "    optimizer.load_state_dict(checkpoints[\"optimizer\"])\n",
    "\n",
    "if (\n",
    "    checkpoints\n",
    "    and \"scheduler\" in checkpoints\n",
    "    and checkpoints[\"scheduler\"] is not None\n",
    "):\n",
    "    logging.info(\"Loading scheduler state dict\")\n",
    "    scheduler.load_state_dict(checkpoints[\"scheduler\"])\n",
    "\n",
    "if params.print_diagnostics:\n",
    "    opts = diagnostics.TensorDiagnosticOptions(\n",
    "        512\n",
    "    )  # allow 4 megabytes per sub-module\n",
    "    diagnostic = diagnostics.attach_diagnostics(model, opts)\n",
    "\n",
    "if params.inf_check:\n",
    "    register_inf_check_hooks(model)\n",
    "\n",
    "librispeech = LibriSpeechAsrDataModule(args)\n",
    "\n",
    "train_cuts = librispeech.train_clean_100_cuts()\n",
    "if params.full_libri:\n",
    "    train_cuts += librispeech.train_clean_360_cuts()\n",
    "    train_cuts += librispeech.train_other_500_cuts()\n",
    "\n",
    "# train_cuts = librispeech.test_clean_cuts() + librispeech.test_other_cuts()\n",
    "\n",
    "def remove_short_and_long_utt(c: Cut):\n",
    "    # Keep only utterances with duration between 1 second and 20 seconds\n",
    "    #\n",
    "    # Caution: There is a reason to select 20.0 here. Please see\n",
    "    # ../local/display_manifest_statistics.py\n",
    "    #\n",
    "    # You should use ../local/display_manifest_statistics.py to get\n",
    "    # an utterance duration distribution for your dataset to select\n",
    "    # the threshold\n",
    "    if c.duration < 1.0 or c.duration > 20.0:\n",
    "        # logging.warning(\n",
    "        #     f\"Exclude cut with ID {c.id} from training. Duration: {c.duration}\"\n",
    "        # )\n",
    "        return False\n",
    "\n",
    "    # In pruned RNN-T, we require that T >= S\n",
    "    # where T is the number of feature frames after subsampling\n",
    "    # and S is the number of tokens in the utterance\n",
    "\n",
    "    # In ./zipformer.py, the conv module uses the following expression\n",
    "    # for subsampling\n",
    "    T = ((c.num_frames - 7) // 2 + 1) // 2\n",
    "    tokens = sp.encode(c.supervisions[0].text, out_type=str)\n",
    "\n",
    "    if T < len(tokens):\n",
    "        logging.warning(\n",
    "            f\"Exclude cut with ID {c.id} from training. \"\n",
    "            f\"Number of frames (before subsampling): {c.num_frames}. \"\n",
    "            f\"Number of frames (after subsampling): {T}. \"\n",
    "            f\"Text: {c.supervisions[0].text}. \"\n",
    "            f\"Tokens: {tokens}. \"\n",
    "            f\"Number of tokens: {len(tokens)}\"\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "train_cuts = train_cuts.filter(remove_short_and_long_utt)\n",
    "\n",
    "# get long text for each recording\n",
    "libri_long_text = get_long_text(train_cuts, sp=sp, make_fst=True)\n",
    "logging.info(f\"len(libri_long_text) = {len(libri_long_text)}\")\n",
    "my_args = {\"libri_long_text\": libri_long_text}\n",
    "\n",
    "get_model_scrach_space(model, k=\"subsampling_factor\", v=params.subsampling_factor, set_value=True)\n",
    "get_model_scrach_space(model, k=\"ctc_beam_size\", v=params.ctc_beam_size, set_value=True)\n",
    "get_model_scrach_space(model, k=\"sp\", v=sp, set_value=True)\n",
    "get_model_scrach_space(model, k=\"params\", v=params, set_value=True)\n",
    "\n",
    "if params.start_batch > 0 and checkpoints and \"sampler\" in checkpoints:\n",
    "    # We only load the sampler's state dict when it loads a checkpoint\n",
    "    # saved in the middle of an epoch\n",
    "    sampler_state_dict = checkpoints[\"sampler\"]\n",
    "else:\n",
    "    sampler_state_dict = None\n",
    "\n",
    "train_dl = librispeech.train_dataloaders(\n",
    "    train_cuts, sampler_state_dict=sampler_state_dict\n",
    ")\n",
    "\n",
    "valid_cuts = librispeech.dev_clean_cuts()\n",
    "valid_cuts += librispeech.dev_other_cuts()\n",
    "valid_dl = librispeech.valid_dataloaders(valid_cuts)\n",
    "\n",
    "# if not params.print_diagnostics:\n",
    "#     scan_pessimistic_batches_for_oom(\n",
    "#         model=model,\n",
    "#         train_dl=train_dl,\n",
    "#         optimizer=optimizer,\n",
    "#         sp=sp,\n",
    "#         params=params,\n",
    "#     )\n",
    "\n",
    "scaler = GradScaler(enabled=params.use_fp16, init_scale=1.0)\n",
    "if checkpoints and \"grad_scaler\" in checkpoints:\n",
    "    logging.info(\"Loading grad scaler state dict\")\n",
    "    scaler.load_state_dict(checkpoints[\"grad_scaler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = params.start_epoch\n",
    "\n",
    "scheduler.step_epoch(epoch - 1)\n",
    "fix_random_seed(params.seed + epoch - 1)\n",
    "train_dl.sampler.set_epoch(epoch - 1)\n",
    "\n",
    "# if tb_writer is not None:\n",
    "#     tb_writer.add_scalar(\"train/epoch\", epoch, params.batch_idx_train)\n",
    "\n",
    "params.cur_epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=params\n",
    "model=model\n",
    "model_avg=model_avg\n",
    "optimizer=optimizer\n",
    "scheduler=scheduler\n",
    "sp=sp\n",
    "train_dl=train_dl\n",
    "valid_dl=valid_dl\n",
    "scaler=scaler\n",
    "tb_writer=None\n",
    "world_size=world_size\n",
    "rank=rank\n",
    "my_args=my_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_one_epoch\n",
    "model.train()\n",
    "\n",
    "tot_loss = MetricsTracker()\n",
    "\n",
    "saved_bad_model = False\n",
    "\n",
    "def save_bad_model(suffix: str = \"\"):\n",
    "    save_checkpoint_impl(\n",
    "        filename=params.exp_dir / f\"bad-model{suffix}-{rank}.pt\",\n",
    "        model=model,\n",
    "        model_avg=model_avg,\n",
    "        params=params,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        sampler=train_dl.sampler,\n",
    "        scaler=scaler,\n",
    "        rank=0,\n",
    "    )\n",
    "\n",
    "get_model_scrach_space(model, k=\"log_priors\", v=None, set_value=True)\n",
    "get_model_scrach_space(model, k=\"priors_T\", v=0, set_value=True)\n",
    "get_model_scrach_space(model, k=\"rank\", v=rank, set_value=True)\n",
    "\n",
    "batch_idx, batch = next(enumerate(train_dl))\n",
    "\n",
    "params.batch_idx_train += 1\n",
    "batch_size = len(batch[\"supervisions\"][\"text\"])\n",
    "\n",
    "supervisions = batch[\"supervisions\"]        \n",
    "my_args[\"supervisions\"] = supervisions\n",
    "\n",
    "params=params\n",
    "model=model\n",
    "sp=sp\n",
    "batch=batch\n",
    "is_training=True\n",
    "my_args=my_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_loss\n",
    "\n",
    "device = model.device if isinstance(model, DDP) else next(model.parameters()).device\n",
    "feature = batch[\"inputs\"]\n",
    "# at entry, feature is (N, T, C)\n",
    "assert feature.ndim == 3\n",
    "feature = feature.to(device)\n",
    "\n",
    "supervisions = batch[\"supervisions\"]\n",
    "feature_lens = supervisions[\"num_frames\"].to(device)\n",
    "\n",
    "batch_idx_train = params.batch_idx_train\n",
    "warm_step = params.warm_step\n",
    "\n",
    "if my_args is None:\n",
    "    texts = batch[\"supervisions\"][\"text\"]\n",
    "    y = sp.encode(texts, out_type=int)\n",
    "    y = k2.RaggedTensor(y)\n",
    "else:\n",
    "    libri_long_text = my_args[\"libri_long_text\"]\n",
    "    cuts = batch['supervisions']['cut']\n",
    "    y = [libri_long_text[tuple(get_uid_key(c.id)[:2])] for c in cuts]\n",
    "    y = (k2.RaggedTensor([[0]] * feature.size(0)), y)\n",
    "    # k2.ragged.create_ragged_tensor([ [1, 2], [5], [], [9] ])\n",
    "    # k2.ragged.create_ragged_tensor([ [1, 2], [5], [], [9] ]).tolist()\n",
    "    get_model_scrach_space(model, k=\"cuts\", v=cuts, set_value=True)\n",
    "\n",
    "get_model_scrach_space(model, k=\"texts\", v=batch[\"supervisions\"][\"text\"], set_value=True)\n",
    "\n",
    "x=feature\n",
    "x_lens=feature_lens\n",
    "y=y\n",
    "prune_range=params.prune_range\n",
    "am_scale=params.am_scale\n",
    "lm_scale=params.lm_scale\n",
    "my_args=my_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if my_args is not None:\n",
    "    y, y_list = y\n",
    "\n",
    "# self.scratch_space[\"my_args\"] = my_args\n",
    "\n",
    "assert x.ndim == 3, x.shape\n",
    "assert x_lens.ndim == 1, x_lens.shape\n",
    "assert y.num_axes == 2, y.num_axes\n",
    "\n",
    "assert x.size(0) == x_lens.size(0) == y.dim0, (x.shape, x_lens.shape, y.dim0)\n",
    "\n",
    "# model.eval()\n",
    "model.train()\n",
    "\n",
    "# Compute encoder outputs\n",
    "encoder_out, encoder_out_lens = model.forward_encoder(x, x_lens)\n",
    "\n",
    "row_splits = y.shape.row_splits(1)\n",
    "y_lens = row_splits[1:] - row_splits[:-1]\n",
    "\n",
    "targets = y.values   # on CPU\n",
    "\n",
    "encoder_out=encoder_out\n",
    "encoder_out_lens=encoder_out_lens\n",
    "targets=y_list\n",
    "target_lengths=y_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ref] I NEVER SELL GOODS WITHOUT KNOWING WHERE I CAN FIND THEM WHEN I WANT THEM AND IF THESE FELLOWS TRY TO PUT THEIR FOREFEET IN THE TROUGH OR START ANY SHOVING AND CROWDING THEY'RE GOING TO FIND ME FORGETTING MY TABLE MANNERS TOO\n",
      "[hyp] I NEVER SELL GOODS WITHOUT KNOWING WHERE I CAN FIND THEM WHEN I WANT THEM AND IF THESE FELLOWS TRY TO PUT THEIR FOREFEET IN THE TROUGH OR START ANY SHOVING AND CROWDING THEY'RE GOING TO FIND ME FORGETTING MY TABLE MANNERS TOO\n",
      "[cut] 3242-67168-0000-6032\n",
      "[ref] NOTHING TO LAY TO HER CHARGE BUT HER BEING THE INVOLUNTARY UNCONSCIOUS OBJECT OF A DECEPTION WHICH HIS PRIDE COULD NOT PARDON AND WHICH A BETTER PRIDE WOULD HAVE BEEN ASHAMED TO OWN\n",
      "[hyp] NOTHING TO LAY TO HER CHARGE BUT HER BEING THE INVOLUNTARY UNCONSCIOUS OBJECT OF A DECEPTION WHICH HIS PRIDE COULD NOT PARDON AND WHICH A BETTER PRIDE WOULD HAVE BEEN ASHAMED TO\n",
      "[cut] 19-227-0035-7874_sp1.1\n",
      "[ref] I WAS AFRAID TO APPROACH OH IS MAMMA TAKEN AWAY WHERE IS SHE WHERE HAVE THEY BROUGHT HER TO I WAS UTTERING UNCONSCIOUSLY VERY NEARLY THE QUESTION WITH WHICH MARY\n",
      "[hyp] WAS AFRAID TO APPROACH OH IS MAMMA TAKEN AWAY WHERE IS SHE WHERE HAVE THEY BROUGHT HER TO I WAS UTTERING UNCONSCIOUSLY VERY NEARLY THE QUESTION WITH WHICH MARY\n",
      "[cut] 2136-5140-0024-9810\n",
      "[ref] L'OLONNOIS NOW STOOD A PROUD VICTOR ON THE DECK OF HIS PRIZE AND BEING A MAN OF PRINCIPLE HE DETERMINED TO LIVE UP TO THE DISTINGUISHED REPUTATION WHICH HE HAD ACQUIRED IN THAT PART OF THE WORLD\n",
      "[hyp] L'OLONNOIS NOW STOOD A PROUD VICTOR ON THE DECK OF HIS PRIZE AND BEING A MAN OF PRINCIPLE HE DETERMINED TO LIVE UP TO THE DISTINGUISHED REPUTATION WHICH HE HAD ACQUIRED IN THAT PART OF THE WORLD\n",
      "[cut] 441-128988-0021-2747\n",
      "[ref] IN FRANCE NO FLOUR AT ALL MAY BE USED TO MAKE THE DELECTABLE PASTRIES AND CAKES WHICH HAVE LONG BEEN THE DELIGHT OF THE FRENCH PEOPLE AND THEIR GUESTS IN ITALY\n",
      "[hyp] FRANCE NO FLOUR AT ALL MAY BE USED TO MAKE THE DELECTABLE PASTRIES AND CAKES WHICH HAVE LONG BEEN THE DELIGHT OF THE FRENCH PEOPLE AND THEIR GUESTS IN\n",
      "[cut] 8051-119902-0026-20556_sp0.9\n",
      "[ref] WHERE BREAKING THROUGH FOUR OR FIVE FEET OF MEALY SNOW THEIR FEET WERE CAUGHT BETWEEN ANGULAR BOULDERS HERE THEY WERE IN DANGER OF BEING LOST BUT AFTER WE HAD REMOVED PACKS AND SADDLES AND ASSISTED THEIR EFFORTS WITH ROPES\n",
      "[hyp] WHERE BREAKING THROUGH FOUR OR FIVE FEET OF MEALY SNOW THEIR FEET WERE CAUGHT BETWEEN ANGULAR BOULDERS HERE THEY WERE IN DANGER OF BEING LOST BUT AFTER WE HAD REMOVED PACKS AND SADDLES AND ASSISTED THEIR EFFORTS WITH ROPES\n",
      "[cut] 4362-15663-0016-1394_sp1.1\n",
      "[ref] AND SO CHARMINGLY DID SHE DEPICT BOTH CHARACTERS THAT WHEN SHE ENDED WITH ORLANDO'S EXIT SHE RECEIVED A LITTLE OVATION FROM THE LISTENING GIRLS IN WHICH MISTER SOUTHARD AND MISS TEBBS JOINED\n",
      "[hyp] DID SHE DEPICT BOTH CHARACTERS THAT WHEN SHE ENDED WITH ORLANDO'S EXIT SHE RECEIVED A LITTLE OVATION FROM THE LISTENING GIRLS IN WHICH MISTER SOUTHARD AND MISS TEBBS JOINED\n",
      "[cut] 587-41619-0013-17310\n",
      "[ref] I TOUCHED IT BEFORE I LEFT THE ROOM WONDERING WHAT THE LITTLE GIRL DREAMED IN THAT BEAUTIFUL BED AND ON THE WAY HOME GRANDMA AND I DISCUSSED ALL THESE THINGS\n",
      "[hyp] TOUCHED IT BEFORE I LEFT THE ROOM WONDERING WHAT THE LITTLE GIRL DREAMED IN THAT BEAUTIFUL BED AND ON THE WAY HOME GRANDMA AND I DISCUSSED ALL THESE THINGS\n",
      "[cut] 2691-156755-0023-21907_sp0.9\n",
      "[ref] THEN YOU TAKE THE MANUSCRIPT TO THE PRINTERS AND THEN WE'LL KICK HIM OUT IF YOU LIKE TO CALL IT THAT I HAVE NO OBJECTION AND AM I TO READ THE VERSES TO YOUR GUESTS AND DISTRIBUTE THEM\n",
      "[hyp] TAKE THE MANUSCRIPT TO THE PRINTERS AND THEN WE'LL KICK HIM OUT IF YOU LIKE TO CALL IT THAT I HAVE NO OBJECTION AND AM I TO READ THE VERSES TO YOUR GUESTS AND DIST\n",
      "[cut] 4441-76250-0034-11506\n",
      "[ref] THE AUTHOR IS PLEASED TO BE ABLE TO PRESENT A SEQUEL TO AUNT JANE'S NIECES THE BOOK WHICH WAS RECEIVED WITH SO MUCH FAVOR LAST YEAR YET IT IS NOT NECESSARY ONE SHOULD HAVE READ THE FIRST BOOK TO FULLY UNDERSTAND THE PRESENT VOLUME\n",
      "[hyp] THE AUTHOR IS PLEASED TO BE ABLE TO PRESENT A SEQUEL TO AUNT JANE'S NIECES THE BOOK WHICH WAS RECEIVED WITH SO MUCH FAVOR LAST YEAR YET IT IS NOT NECESSARY ONE SHOULD HAVE READ THE FIRST BOOK TO FULLY UNDERSTAND THE PRESENT VOLUME\n",
      "[cut] 4481-17498-0000-11039_sp1.1\n"
     ]
    }
   ],
   "source": [
    "# forward_ctc_long_form\n",
    "\n",
    "from icefall.decode import get_lattice, one_best_decoding\n",
    "from icefall.utils import get_alignments, get_texts\n",
    "\n",
    "\n",
    "ctc_output = model.ctc_output(encoder_out)  # (N, T, C)\n",
    "\n",
    "supervision_segments, texts, indices = model.encode_supervisions(targets, target_lengths, encoder_out_lens)\n",
    "\n",
    "y_list = targets\n",
    "_y_list = [y_list[i] for i in indices.tolist()]\n",
    "decoding_graph = k2.create_fsa_vec(_y_list)\n",
    "decoding_graph = k2.arc_sort(decoding_graph)\n",
    "decoding_graph = decoding_graph.to(encoder_out.device)\n",
    "\n",
    "log_probs = ctc_output\n",
    "\n",
    "lattice = get_lattice(\n",
    "    nnet_output=log_probs,\n",
    "    decoding_graph=decoding_graph,\n",
    "    supervision_segments=supervision_segments,\n",
    "    search_beam=15,\n",
    "    output_beam=6,\n",
    "    min_active_states=30,\n",
    "    max_active_states=10000,\n",
    "    subsampling_factor=model.scratch_space[\"subsampling_factor\"],\n",
    ")\n",
    "\n",
    "for i in range(10):\n",
    "    model.check_lattice2(lattice, indices, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'best_train_loss': 0.13572675826983707, 'best_valid_loss': 0.2689881270166117, 'best_train_epoch': 14, 'best_valid_epoch': 14, 'batch_idx_train': 10603, 'log_interval': 50, 'reset_interval': 200, 'valid_interval': 1000, 'feature_dim': 80, 'subsampling_factor': 4, 'warm_step': 2000, 'env_info': {'k2-version': '1.24.4', 'k2-build-type': 'Debug', 'k2-with-cuda': True, 'k2-git-sha1': '415fe1f446fffe1d9e7219b5033966294c0b430c', 'k2-git-date': 'Wed Dec 20 21:38:57 2023', 'lhotse-version': '1.20.0.dev+git.c6788492.clean', 'torch-version': '2.1.2', 'torch-cuda-available': True, 'torch-cuda-version': '11.8', 'python-version': '3.1', 'icefall-git-branch': 'noseg', 'icefall-git-sha1': '9c12663-dirty', 'icefall-git-date': 'Sun Feb 4 04:05:36 2024', 'icefall-path': '/scratch4/skhudan1/rhuang25/icefall', 'k2-path': '/scratch4/skhudan1/rhuang25/k2/k2/python/k2/__init__.py', 'lhotse-path': '/scratch4/skhudan1/rhuang25/lhotse/lhotse/__init__.py', 'hostname': 'gpu08', 'IP address': '172.20.30.8'}, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 30, 'start_epoch': 2, 'start_batch': 0, 'exp_dir': PosixPath('/home/rhuang25/work/icefall/egs/librispeech/ASR/zipformer_no_seg/exp-test'), 'bpe_model': '/home/rhuang25/work/icefall/egs/librispeech/ASR/data/lang_bpe_500/bpe.model', 'base_lr': 0.045, 'lr_batches': 7500, 'lr_epochs': 3.5, 'ref_duration': 600, 'context_size': 2, 'prune_range': 5, 'lm_scale': 0.25, 'am_scale': 0.0, 'simple_loss_scale': 0.5, 'ctc_loss_scale': 1.0, 'seed': 42, 'print_diagnostics': False, 'inf_check': False, 'save_every_n': 4000, 'keep_last_k': 30, 'average_period': 200, 'use_fp16': False, 'num_encoder_layers': '2,2,3,4,3,2', 'downsampling_factor': '1,2,4,8,4,2', 'feedforward_dim': '512,768,1024,1536,1024,768', 'num_heads': '4,4,4,8,4,4', 'encoder_dim': '192,256,384,512,384,256', 'query_head_dim': '32', 'value_head_dim': '12', 'pos_head_dim': '4', 'pos_dim': 48, 'encoder_unmasked_dim': '192,192,256,256,256,192', 'cnn_module_kernel': '31,31,15,15,15,31', 'decoder_dim': 512, 'joiner_dim': 512, 'causal': False, 'chunk_size': '16,32,64,-1', 'left_context_frames': '64,128,256,-1', 'use_transducer': False, 'use_ctc': True, 'ctc_beam_size': 4, 'full_libri': False, 'mini_libri': False, 'manifest_dir': PosixPath('/home/rhuang25/work/icefall/egs/librispeech/ASR/data/fbank'), 'max_duration': 400, 'bucketing_sampler': True, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'drop_last': True, 'return_cuts': True, 'num_workers': 2, 'enable_spec_aug': True, 'spec_aug_time_warp_factor': 80, 'enable_musan': True, 'input_strategy': 'PrecomputedFeatures', 'epoch': 2, 'avg': 1, 'blank_id': 0, 'vocab_size': 500, 'cur_epoch': 2}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hltcoe/rhuang/mambaforge/envs/aligner5/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligner5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
